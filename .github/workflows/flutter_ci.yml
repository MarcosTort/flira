# .github/workflows/ai-code-review-fixed.yml
name: ğŸ¤– AI Code Review (Fixed)

on:
  pull_request:
    types: [opened, synchronize, reopened]
    # Exclude draft PRs to save resources
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.github/workflows/**'
      - 'README*'

# Ensure only one review runs at a time per PR
concurrency:
  group: ai-review-${{ github.event.pull_request.number }}
  cancel-in-progress: true

env:
  # Runner optimization settings
  PYTHONUNBUFFERED: 1
  PYTHONDONTWRITEBYTECODE: 1
  # GitHub context
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  REPO_NAME: ${{ github.repository }}
  PR_NUMBER: ${{ github.event.pull_request.number }}
  HEAD_SHA: ${{ github.event.pull_request.head.sha }}
  BASE_SHA: ${{ github.event.pull_request.base.sha }}
  # LM Studio configuration
  INFERENCE_SERVER_URL: ${{ vars.LMSTUDIO_API_URL || 'http://127.0.0.1:8080' }}
  LMSTUDIO_API_URL: ${{ vars.LMSTUDIO_API_URL || 'http://127.0.0.1:8080' }}
  # Performance tuning
  MAX_CONCURRENT_WORKERS: ${{ vars.MAX_WORKERS || '6' }}
  MAX_COMMENTS_PER_FILE: ${{ vars.MAX_COMMENTS_PER_FILE || '8' }}
  REQUEST_TIMEOUT: ${{ vars.REQUEST_TIMEOUT || '45' }}
  TEMPERATURE: ${{ vars.AI_TEMPERATURE || '0.2' }}
  MAX_TOKENS: ${{ vars.MAX_TOKENS || '200' }}

jobs:
  ai-code-review:
    name: ğŸ¤– AI Code Review
    runs-on: self-hosted
    timeout-minutes: 30  # Prevent runaway jobs
    
    # Skip if PR is draft or created by bots
    if: >
      github.event.pull_request.draft == false &&
      !contains(github.event.pull_request.user.login, 'bot') &&
      !contains(github.event.pull_request.user.login, 'dependabot')
    
    steps:
      - name: ğŸ“‹ Checkout Repository
        uses: actions/checkout@v4
        with:
          # Fetch full history for better context
          fetch-depth: 0
          # Checkout the PR head
          ref: ${{ github.event.pull_request.head.sha }}
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5  # Updated to v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: ğŸ“¦ Install Dependencies
        run: |
          echo "ğŸ”§ Installing enhanced AI review dependencies..."
          pip install --upgrade pip
          pip install -r requirements.txt
          echo "âœ… Dependencies installed successfully"
      
      - name: ğŸƒ Check Runner Environment
        run: |
          echo "ğŸƒ Runner Environment Information:"
          echo "Runner Name: $RUNNER_NAME"
          echo "Runner OS: $RUNNER_OS"
          echo "Runner Architecture: $RUNNER_ARCH"
          echo "Runner Version: $(cat /opt/actions-runner/.runner 2>/dev/null | jq -r '.agentVersion' 2>/dev/null || echo 'Unknown')"
          echo "Available CPUs: $(nproc)"
          echo "Available Memory: $(free -h | grep '^Mem:' | awk '{print $2}')"
          echo "Available Disk: $(df -h / | tail -1 | awk '{print $4}')"
          echo "Python Version: $(python --version)"
          echo "Working Directory: $(pwd)"
          echo "Repository: $GITHUB_REPOSITORY"
          echo "PR Number: $PR_NUMBER"
      
      - name: ğŸ”Œ Verify LM Studio Connection
        run: |
          echo "ğŸ”Œ Checking LM Studio availability..."
          
          # Wait for LM Studio to be ready (with timeout)
          timeout=60
          counter=0
          
          until curl -f -s "${LMSTUDIO_API_URL}/v1/models" > /dev/null; do
            if [ $counter -ge $timeout ]; then
              echo "âŒ LM Studio not available after ${timeout}s timeout"
              echo "ğŸ’¡ Please ensure:"
              echo "   - LM Studio is running on the self-hosted runner"
              echo "   - A model is loaded and ready"
              echo "   - API server is accessible at: $LMSTUDIO_API_URL"
              exit 1
            fi
            
            echo "â³ Waiting for LM Studio... (${counter}s/${timeout}s)"
            sleep 5
            counter=$((counter + 5))
          done
          
          echo "âœ… LM Studio is ready!"
          
          # Get model information
          echo "ğŸ¤– Available models:"
          curl -s "${LMSTUDIO_API_URL}/v1/models" | python -m json.tool || echo "Could not parse model response"
      
      - name: ğŸ—„ï¸ Setup Cache
        run: |
          echo "ğŸ—„ï¸ Setting up cache directory..."
          
          # Create cache directory in runner temp
          CACHE_DIR="${RUNNER_TEMP}/ai_review_cache"
          mkdir -p "$CACHE_DIR"
          
          echo "ğŸ“Š Cache directory: $CACHE_DIR"
          echo "ğŸ“Š Cache size before: $(du -sh "$CACHE_DIR" 2>/dev/null || echo '0 B')"
          
          # Clean old cache entries (older than 7 days)
          find "$CACHE_DIR" -name "*.json" -mtime +7 -delete 2>/dev/null || true
          
          echo "ğŸ“Š Cache size after cleanup: $(du -sh "$CACHE_DIR" 2>/dev/null || echo '0 B')"
          echo "ğŸ“Š Cache entries: $(find "$CACHE_DIR" -name "*.json" | wc -l)"
      
      - name: ğŸ¤– Run AI Code Review
        id: ai-review
        run: |
          echo "ğŸš€ Starting AI Code Review..."
          
          # Set additional environment variables for the script
          export CACHE_DIR="${RUNNER_TEMP}/ai_review_cache"
          export LOG_DIR="${RUNNER_TEMP}/ai_review_logs"
          mkdir -p "$LOG_DIR"
          
          # Enable debug logging if runner debug is enabled
          if [ "$RUNNER_DEBUG" = "1" ]; then
            export PYTHONVERBOSE=1
          fi
          
          # Check if enhanced script exists, fallback to original if not
          if [ -f "scripts/runner_optimized_ai_review.py" ]; then
            echo "ğŸš€ Using runner-optimized version"
            python scripts/runner_optimized_ai_review.py
          elif [ -f "scripts/enhanced_local_ai_review.py" ]; then
            echo "âš¡ Using enhanced version"
            python scripts/enhanced_local_ai_review.py
          elif [ -f "scripts/local_ai_review.py" ]; then
            echo "ğŸŒ Using legacy version"
            python scripts/local_ai_review.py
          else
            echo "âŒ No AI review script found"
            exit 1
          fi
        continue-on-error: false
        timeout-minutes: 25
      
      - name: ğŸ“Š Review Statistics
        if: always()
        run: |
          echo "ğŸ“Š Final Review Statistics:"
          echo "Files Processed: ${{ steps.ai-review.outputs.files_processed || 'N/A' }}"
          echo "Lines Analyzed: ${{ steps.ai-review.outputs.lines_analyzed || 'N/A' }}"
          echo "Issues Found: ${{ steps.ai-review.outputs.issues_found || 'N/A' }}"
          echo "Processing Time: ${{ steps.ai-review.outputs.processing_time || 'N/A' }}s"
          echo "Cache Hit Rate: ${{ steps.ai-review.outputs.cache_hit_rate || 'N/A' }}%"
          echo "Issue Rate: ${{ steps.ai-review.outputs.issue_rate || 'N/A' }}%"
          echo "Lines/Second: ${{ steps.ai-review.outputs.lines_per_second || 'N/A' }}"
          
          # Show system resource usage
          echo ""
          echo "ğŸƒ Final System Resources:"
          echo "CPU Usage: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1 2>/dev/null || echo 'N/A')%"
          echo "Memory Usage: $(free | grep Mem | awk '{printf("%.1f%%", $3/$2 * 100.0)}' 2>/dev/null || echo 'N/A')"
          echo "Disk Usage: $(df / | tail -1 | awk '{print $5}' 2>/dev/null || echo 'N/A')"
      
      - name: ğŸ“ Archive Logs
        if: always()
        uses: actions/upload-artifact@v4  # Updated to v4
        with:
          name: ai-review-logs-pr-${{ github.event.pull_request.number }}
          path: ${{ runner.temp }}/ai_review_logs/
          retention-days: 7
          if-no-files-found: ignore  # Don't fail if no logs
      
      - name: ğŸ§¹ Cleanup
        if: always()
        run: |
          echo "ğŸ§¹ Cleaning up temporary files..."
          
          # Clean up temporary files but preserve cache
          rm -rf "${RUNNER_TEMP}/ai_review_temp_*" 2>/dev/null || true
          
          # Show final cache stats
          CACHE_DIR="${RUNNER_TEMP}/ai_review_cache"
          if [ -d "$CACHE_DIR" ]; then
            echo "ğŸ“Š Final cache size: $(du -sh "$CACHE_DIR" 2>/dev/null || echo 'Unknown')"
            echo "ğŸ“Š Final cache entries: $(find "$CACHE_DIR" -name "*.json" 2>/dev/null | wc -l || echo 'Unknown')"
          fi
          
          echo "âœ… Cleanup completed"
      
      # Optional: Notify on failure
      - name: ğŸ’¬ Notify on Failure
        if: failure()
        uses: actions/github-script@v7  # Updated to v7
        with:
          script: |
            const issue_number = context.payload.pull_request.number;
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const message = `ğŸ¤–âŒ **AI Code Review Failed**
            
            The automated code review encountered an error. Please check the [workflow logs](${runUrl}) for details.
            
            **Common issues:**
            - LM Studio not running or model not loaded
            - Insufficient system resources  
            - Network connectivity issues
            - Missing dependencies
            
            **Quick fixes:**
            1. Check LM Studio is running: \`curl http://127.0.0.1:8080/v1/models\`
            2. Verify system resources: \`free -h && df -h\`
            3. Check runner logs for specific errors
            
            The review will be retried automatically on the next push.`;
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue_number,
              body: message
            });

  # Optional: Summary job for multiple reviews
  review-summary:
    name: ğŸ“‹ Review Summary
    runs-on: self-hosted
    needs: [ai-code-review]
    if: always()
    
    steps:
      - name: ğŸ“‹ Generate Summary
        run: |
          echo "ğŸ“‹ AI Code Review Summary for PR #${{ github.event.pull_request.number }}"
          echo "Status: ${{ needs.ai-code-review.result }}"
          echo "Runner: $RUNNER_NAME (v$(cat /opt/actions-runner/.runner 2>/dev/null | jq -r '.agentVersion' 2>/dev/null || echo 'Unknown'))"
          
          if [ "${{ needs.ai-code-review.result }}" = "success" ]; then
            echo "âœ… AI Code Review completed successfully"
            echo "ğŸ“Š Check the PR for detailed feedback"
          else
            echo "âŒ AI Code Review failed or was cancelled"
            echo "ğŸ” Check the workflow logs for details"
          fi