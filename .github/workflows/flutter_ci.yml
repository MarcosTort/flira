# .github/workflows/ai-code-review.yml
name: 🤖 AI Code Review

on:
  pull_request:
    types: [opened, synchronize, reopened]
    # Exclude draft PRs to save resources
    # paths-ignore:
    #   - '**.md'
    #   - 'docs/**'
    #   - '.github/**'

# Ensure only one review runs at a time per PR
concurrency:
  group: ai-review-${{ github.event.pull_request.number }}
  cancel-in-progress: true

env:
  # Runner optimization settings
  PYTHONUNBUFFERED: 1
  PYTHONDONTWRITEBYTECODE: 1
  # GitHub context
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  REPO_NAME: ${{ github.repository }}
  PR_NUMBER: ${{ github.event.pull_request.number }}
  HEAD_SHA: ${{ github.event.pull_request.head.sha }}
  BASE_SHA: ${{ github.event.pull_request.base.sha }}
  # LM Studio configuration
  INFERENCE_SERVER_URL: ${{ vars.LMSTUDIO_API_URL || 'http://127.0.0.1:8080' }}
  LMSTUDIO_API_URL: ${{ vars.LMSTUDIO_API_URL || 'http://127.0.0.1:8080' }}
  # Performance tuning
  MAX_CONCURRENT_WORKERS: ${{ vars.MAX_WORKERS || '6' }}
  MAX_COMMENTS_PER_FILE: ${{ vars.MAX_COMMENTS_PER_FILE || '8' }}
  REQUEST_TIMEOUT: ${{ vars.REQUEST_TIMEOUT || '45' }}
  TEMPERATURE: ${{ vars.AI_TEMPERATURE || '0.2' }}
  MAX_TOKENS: ${{ vars.MAX_TOKENS || '200' }}

jobs:
  ai-code-review:
    name: 🤖 AI Code Review
    runs-on: self-hosted
    timeout-minutes: 30  # Prevent runaway jobs
    
    # Skip if PR is draft or created by bots
    if: >
      github.event.pull_request.draft == false &&
      !contains(github.event.pull_request.user.login, 'bot') &&
      !contains(github.event.pull_request.user.login, 'dependabot')
    
    steps:
      - name: 📋 Checkout Repository
        uses: actions/checkout@v4
        with:
          # Fetch full history for better context
          fetch-depth: 0
          # Checkout the PR head
          ref: ${{ github.event.pull_request.head.sha }}
      
      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: 📦 Install Dependencies
        run: |
          echo "🔧 Installing enhanced AI review dependencies..."
          pip install --upgrade pip
          pip install -r requirements.txt
          echo "✅ Dependencies installed successfully"
      
      - name: 🏃 Check Runner Environment
        run: |
          echo "🏃 Runner Environment Information:"
          echo "Runner Name: $RUNNER_NAME"
          echo "Runner OS: $RUNNER_OS"
          echo "Runner Architecture: $RUNNER_ARCH"
          echo "Available CPUs: $(nproc)"
          echo "Available Memory: $(free -h | grep '^Mem:' | awk '{print $2}')"
          echo "Available Disk: $(df -h / | tail -1 | awk '{print $4}')"
          echo "Python Version: $(python --version)"
          echo "Working Directory: $(pwd)"
          echo "Repository: $GITHUB_REPOSITORY"
          echo "PR Number: $PR_NUMBER"
      
      - name: 🔌 Verify LM Studio Connection
        run: |
          echo "🔌 Checking LM Studio availability..."
          
          # Wait for LM Studio to be ready (with timeout)
          timeout=60
          counter=0
          
          until curl -f -s "${LMSTUDIO_API_URL}/v1/models" > /dev/null; do
            if [ $counter -ge $timeout ]; then
              echo "❌ LM Studio not available after ${timeout}s timeout"
              echo "💡 Please ensure:"
              echo "   - LM Studio is running on the self-hosted runner"
              echo "   - A model is loaded and ready"
              echo "   - API server is accessible at: $LMSTUDIO_API_URL"
              exit 1
            fi
            
            echo "⏳ Waiting for LM Studio... (${counter}s/${timeout}s)"
            sleep 5
            counter=$((counter + 5))
          done
          
          echo "✅ LM Studio is ready!"
          
          # Get model information
          echo "🤖 Available models:"
          curl -s "${LMSTUDIO_API_URL}/v1/models" | python -m json.tool || echo "Could not parse model response"
      
      - name: 🗄️ Setup Cache
        run: |
          echo "🗄️ Setting up cache directory..."
          
          # Create cache directory in runner temp
          CACHE_DIR="${RUNNER_TEMP}/ai_review_cache"
          mkdir -p "$CACHE_DIR"
          
          echo "📊 Cache directory: $CACHE_DIR"
          echo "📊 Cache size before: $(du -sh "$CACHE_DIR" 2>/dev/null || echo '0 B')"
          
          # Clean old cache entries (older than 7 days)
          find "$CACHE_DIR" -name "*.json" -mtime +7 -delete 2>/dev/null || true
          
          echo "📊 Cache size after cleanup: $(du -sh "$CACHE_DIR" 2>/dev/null || echo '0 B')"
          echo "📊 Cache entries: $(find "$CACHE_DIR" -name "*.json" | wc -l)"
      
      - name: 🤖 Run AI Code Review
        id: ai-review
        run: |
          echo "🚀 Starting AI Code Review..."
          
          # Set additional environment variables for the script
          export CACHE_DIR="${RUNNER_TEMP}/ai_review_cache"
          export LOG_DIR="${RUNNER_TEMP}/ai_review_logs"
          mkdir -p "$LOG_DIR"
          
          # Enable debug logging if runner debug is enabled
          if [ "$RUNNER_DEBUG" = "1" ]; then
            export PYTHONVERBOSE=1
          fi
          
          # Run the enhanced AI review
          python scripts/runner_optimized_ai_review.py
        continue-on-error: false
        timeout-minutes: 25
      
      - name: 📊 Review Statistics
        if: always()
        run: |
          echo "📊 Final Review Statistics:"
          echo "Files Processed: ${{ steps.ai-review.outputs.files_processed || 'N/A' }}"
          echo "Lines Analyzed: ${{ steps.ai-review.outputs.lines_analyzed || 'N/A' }}"
          echo "Issues Found: ${{ steps.ai-review.outputs.issues_found || 'N/A' }}"
          echo "Processing Time: ${{ steps.ai-review.outputs.processing_time || 'N/A' }}s"
          echo "Cache Hit Rate: ${{ steps.ai-review.outputs.cache_hit_rate || 'N/A' }}%"
          echo "Issue Rate: ${{ steps.ai-review.outputs.issue_rate || 'N/A' }}%"
          echo "Lines/Second: ${{ steps.ai-review.outputs.lines_per_second || 'N/A' }}"
          
          # Show system resource usage
          echo ""
          echo "🏃 Final System Resources:"
          echo "CPU Usage: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)%"
          echo "Memory Usage: $(free | grep Mem | awk '{printf("%.1f%%", $3/$2 * 100.0)}')"
          echo "Disk Usage: $(df / | tail -1 | awk '{print $5}')"
      
      - name: 📁 Archive Logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: ai-review-logs-pr-${{ github.event.pull_request.number }}
          path: ${{ runner.temp }}/ai_review_logs/
          retention-days: 7
      
      - name: 🧹 Cleanup
        if: always()
        run: |
          echo "🧹 Cleaning up temporary files..."
          
          # Clean up temporary files but preserve cache
          rm -rf "${RUNNER_TEMP}/ai_review_temp_*" 2>/dev/null || true
          rm -rf "${RUNNER_TEMP}/ai_review_logs" 2>/dev/null || true
          
          # Show final cache stats
          CACHE_DIR="${RUNNER_TEMP}/ai_review_cache"
          if [ -d "$CACHE_DIR" ]; then
            echo "📊 Final cache size: $(du -sh "$CACHE_DIR")"
            echo "📊 Final cache entries: $(find "$CACHE_DIR" -name "*.json" | wc -l)"
          fi
          
          echo "✅ Cleanup completed"
      
      # Optional: Notify on failure
      - name: 💬 Notify on Failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            const issue_number = context.payload.pull_request.number;
            const message = `🤖❌ **AI Code Review Failed**
            
            The automated code review encountered an error. Please check the [workflow logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details.
            
            Common issues:
            - LM Studio not running or model not loaded
            - Insufficient system resources
            - Network connectivity issues
            
            The review will be retried automatically on the next push.`;
            
            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue_number,
              body: message
            });

  # Optional: Summary job for multiple reviews
  review-summary:
    name: 📋 Review Summary
    runs-on: self-hosted
    needs: [ai-code-review]
    if: always()
    
    steps:
      - name: 📋 Generate Summary
        run: |
          echo "📋 AI Code Review Summary for PR #${{ github.event.pull_request.number }}"
          echo "Status: ${{ needs.ai-code-review.result }}"
          
          if [ "${{ needs.ai-code-review.result }}" = "success" ]; then
            echo "✅ AI Code Review completed successfully"
            echo "📊 Check the PR for detailed feedback"
          else
            echo "❌ AI Code Review failed or was cancelled"
            echo "🔍 Check the workflow logs for details"
          fi